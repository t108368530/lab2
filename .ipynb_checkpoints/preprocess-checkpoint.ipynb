{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10187.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10721.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10138.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random\n",
    "import os\n",
    "from random import random, uniform\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "allFilesList: list = []\n",
    "\n",
    "dirName = [\"train\", \"valid\", \"pitchShiftTest\"]\n",
    "trainFolders: list = sorted(os.listdir(f\"./{dirName[0]}/\"))\n",
    "trainList: list = []\n",
    "\n",
    "validFolders: list = sorted(os.listdir(f\"./{dirName[1]}/\"))\n",
    "validList: list = []\n",
    "\n",
    "pitchShiftFolders: list = sorted(os.listdir(f\"./{dirName[2]}/\"))\n",
    "pitchShiftList: list = []\n",
    "# categorys: list = [f\"{i}\".rjust(2, \"0\") for i in range(1, 11)]\n",
    "categorysCounts: dict = {\"train\": {}, \"valid\": {}, \"pitch_shift\": {}}\n",
    "\n",
    "for folder in tqdm(trainFolders):\n",
    "    files = os.listdir(\"./train/\" + folder)\n",
    "    for num, file in enumerate(files):\n",
    "        allFilesList.append(\"./train/\" + folder + \"/\" + file)\n",
    "        trainList.append(folder + \"/\" + file)\n",
    "        categorysCounts[\"train\"][folder] = num + 1\n",
    "\n",
    "\n",
    "for folder in tqdm(validFolders):\n",
    "    files = os.listdir(\"./valid/\" + folder)\n",
    "    for num, file in enumerate(files):\n",
    "        allFilesList.append(\"./valid/\" + folder + \"/\" + file)\n",
    "        validList.append(folder + \"/\" + file)\n",
    "        categorysCounts[\"valid\"][folder] = num + 1\n",
    "\n",
    "for folder in tqdm(pitchShiftFolders):\n",
    "    files = os.listdir(\"./pitchShiftTest/\" + folder)\n",
    "    for num, file in enumerate(files):\n",
    "        allFilesList.append(\"./pitchShiftTest/\" + folder + \"/\" + file)\n",
    "        pitchShiftList.append(folder + \"/\" + file)\n",
    "        categorysCounts[\"pitch_shift\"][folder] = num + 1\n",
    "\n",
    "trainList = sorted(trainList)\n",
    "validList = sorted(validList)\n",
    "pitchShiftList = sorted(pitchShiftList)\n",
    "allFilesList = sorted(allFilesList)\n",
    "\n",
    "\n",
    "def extractFeatures(\n",
    "    path: str, ps: bool = False, ts: bool = False, st: int = 4\n",
    ") -> np.ndarray:\n",
    "    \"\"\"[提取特徵]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        ps {bool} \n",
    "    Returns:\n",
    "        np.ndarray -- \n",
    "               [\n",
    "                mfccs,\n",
    "                mfcc_delta,\n",
    "                mfcc_delta2,\n",
    "                chroma,\n",
    "                mel,\n",
    "                contrast,\n",
    "                tonnetz,\n",
    "                cent,\n",
    "                flatness,\n",
    "                rolloff,\n",
    "                rms,\n",
    "                ]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X, sampleRate = librosa.load(\n",
    "            path, offset=0.0, res_type=\"kaiser_best\", dtype=np.float32,\n",
    "        )\n",
    "        if ps:\n",
    "            X = librosa.effects.pitch_shift(X, sampleRate, n_steps=st)\n",
    "\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sampleRate).T, axis=0)\n",
    "        tonnetz = np.mean(\n",
    "            librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sampleRate).T,\n",
    "            axis=0,\n",
    "        )\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sampleRate, n_mfcc=40).T, axis=0)\n",
    "        mfcc_delta = librosa.feature.delta(mfccs)  # TONY\n",
    "        mfcc_delta2 = librosa.feature.delta(mfccs, order=2)  # TONY\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampleRate).T, axis=0)\n",
    "        contrast = np.mean(\n",
    "            librosa.feature.spectral_contrast(S=stft, sr=sampleRate).T, axis=0\n",
    "        )\n",
    "        ###### ADD NEW FEATURES (SPECTRAL RELATED)##### 24-SEP\n",
    "        cent = np.mean(librosa.feature.spectral_centroid(y=X, sr=sampleRate).T, axis=0)\n",
    "        flatness = np.mean(librosa.feature.spectral_flatness(y=X).T, axis=0)\n",
    "        rolloff = np.mean(\n",
    "            librosa.feature.spectral_rolloff(S=stft, sr=sampleRate).T, axis=0\n",
    "        )\n",
    "        rms = np.mean(librosa.feature.rms(S=stft).T, axis=0)\n",
    "        ext_features = np.hstack(\n",
    "            [\n",
    "                mfccs,\n",
    "                mfcc_delta,\n",
    "                mfcc_delta2,\n",
    "                chroma,\n",
    "                mel,\n",
    "                contrast,\n",
    "                tonnetz,\n",
    "                cent,\n",
    "                flatness,\n",
    "                rolloff,\n",
    "                rms,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file:%s\" % (path))\n",
    "        return None\n",
    "\n",
    "    return np.array(ext_features)\n",
    "\n",
    "\n",
    "def creatSets(\n",
    "    path: str, dataList: list, shape: int, ps: bool = False, st: float = 4\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"[創建訓練資料]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        dataList {list} -- [檔案列表]\n",
    "        shape {tuple} -- [矩陣維度]\n",
    "    Returns:\n",
    "        [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "    \"\"\"\n",
    "    xArray = np.zeros([len(dataList), shape])\n",
    "    yArray = np.zeros([len(dataList)])\n",
    "\n",
    "    for index, file in tqdm(enumerate(dataList)):\n",
    "        file = path + file\n",
    "        try:\n",
    "            xArray[index] = extractFeatures(file, ps=ps, st=st)\n",
    "            yArray[index] = file.rsplit(\"/\", 2)[1]\n",
    "        except ValueError:\n",
    "            print(index, file, ValueError)\n",
    "    return (xArray, yArray)\n",
    "\n",
    "\n",
    "def creatAugmentSets(\n",
    "    path: str, dataList: list, shape: int, percent: float = 0\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"[創建訓練資料]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        dataList {list} -- [檔案列表]\n",
    "        shape {tuple} -- [矩陣維度]\n",
    "    Returns:\n",
    "        [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "    \"\"\"\n",
    "    fileCounts = len(dataList)\n",
    "    xArray = np.zeros([fileCounts * 5, shape])\n",
    "    yArray = np.zeros([fileCounts * 5], dtype=np.int8)\n",
    "\n",
    "    for index, file in tqdm(enumerate(dataList)):\n",
    "        file = path + file\n",
    "        try:\n",
    "            st = uniform(1.0, 2.0)\n",
    "            st2 = uniform(2.0, 3.0)\n",
    "            st3 = uniform(3.0, 5.0)\n",
    "            st4 = uniform(5.0, 7.0)\n",
    "            ps = random() > percent\n",
    "\n",
    "            xArray[index] = extractFeatures(file)\n",
    "            yArray[index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts + index] = extractFeatures(file, ps=ps, st=st)\n",
    "            yArray[fileCounts + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 2 + index] = extractFeatures(file, ps=ps, st=st2)\n",
    "            yArray[fileCounts * 2 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 3 + index] = extractFeatures(file, ps=ps, st=st3)\n",
    "            yArray[fileCounts * 3 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 4 + index] = extractFeatures(file, ps=ps, st=st4)\n",
    "            yArray[fileCounts * 4 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "        except ValueError:\n",
    "            print(index, file, ValueError)\n",
    "    return (xArray, yArray)\n",
    "\n",
    "\n",
    "def zScore(x):\n",
    "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [04:57,  1.49s/it]\n",
      "74it [00:17,  4.39it/s]"
     ]
    }
   ],
   "source": [
    "trainData, trainLabel = creatAugmentSets(\n",
    "    \"./train/\", trainList, extractFeatures(\"./train/\" + trainList[0]).shape[0], 0\n",
    ")\n",
    "\n",
    "\n",
    "validData, validLabel = creatSets(\n",
    "    \"./valid/\", validList, extractFeatures(\"./valid/\" + validList[0]).shape[0], False\n",
    ")\n",
    "\n",
    "\n",
    "pitchShiftTestData, pitchShiftTestLabel = creatSets(\n",
    "    \"./pitchShiftTest/\",\n",
    "    pitchShiftList,\n",
    "    extractFeatures(\"./pitchShiftTest/\" + pitchShiftList[0]).shape[0],\n",
    "    True,\n",
    "    3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存資料\n",
    "- 訓練資料\n",
    "- 驗證資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(trainData.shape[0])\n",
    "trainData = trainData[indices]\n",
    "trainLabel = trainLabel[indices]\n",
    "\n",
    "indices = np.random.permutation(validData.shape[0])\n",
    "validData = validData[indices]\n",
    "validLabel = validLabel[indices]\n",
    "\n",
    "indices = np.random.permutation(pitchShiftTestData.shape[0])\n",
    "pitchShiftTestData = pitchShiftTestData[indices]\n",
    "pitchShiftTestLabel = pitchShiftTestLabel[indices]\n",
    "\n",
    "np.save(\"trainData.npy\", zScore(trainData))\n",
    "np.save(\"trainLabel.npy\", trainLabel.astype(np.int))\n",
    "\n",
    "np.save(\"validData.npy\", zScore(validData))\n",
    "np.save(\"validLabel.npy\", validLabel.astype(np.int))\n",
    "\n",
    "np.save(\"pitchShiftTestData.npy\", zScore(pitchShiftTestData))\n",
    "np.save(\"pitchShiftTestLabel.npy\", pitchShiftTestLabel.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractMelSpec(\n",
    "#     path: str, flip: bool = False, ps: bool = False, st: int = 4\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"[提取mel頻譜]\n",
    "\n",
    "#     Arguments:\n",
    "#         path {str} -- [路徑]\n",
    "\n",
    "#     Keyword Arguments:\n",
    "#         flip {bool} -- [矩陣反轉] (default: {False})\n",
    "#         ps {bool} -- [是否調整音階]] (default: {False})\n",
    "#         st {int} -- [調整幾階]] (default: {4})\n",
    "\n",
    "#     Returns:\n",
    "#         np.ndarray -- [mel頻譜]\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         sig, rate = librosa.load(\n",
    "#             path, offset=0.0, res_type=\"kaiser_fast\", dtype=np.float32\n",
    "#         )\n",
    "#         if len(sig) < 22050:  # pad shorter than 1 sec audio with ramp to zero\n",
    "#             sig = np.pad(sig, (0, 22050 - len(sig)), \"linear_ramp\")\n",
    "#         if ps:\n",
    "#             sig = librosa.effects.pitch_shift(sig, rate, n_steps=st)\n",
    "#         db = librosa.amplitude_to_db(\n",
    "#             librosa.stft(sig[:22050], hop_length=256, center=False), ref=np.max\n",
    "#         )\n",
    "#         spec = librosa.feature.melspectrogram(S=db, n_mels=128).T\n",
    "#         if flip:\n",
    "#             spec = np.flipud(spec)\n",
    "#     except Exception as e:\n",
    "#         print(\"Error encountered while parsing file:%s\" % (path))\n",
    "#         return None\n",
    "#     return spec.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# def creatMelSpecSets(\n",
    "#     path: str, dataList: list, shape: tuple\n",
    "# ) -> (np.ndarray, np.ndarray):\n",
    "#     \"\"\"[創建訓練梅爾頻譜資料]\n",
    "\n",
    "#     Arguments:\n",
    "#         path {str} -- [路徑]\n",
    "#         dataList {list} -- [檔案列表]\n",
    "#         shape {tuple} -- [矩陣維度]\n",
    "#     Returns:\n",
    "#         [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "#     \"\"\"\n",
    "#     shape1, shape2 = shape\n",
    "#     xArray = np.zeros([len(dataList), shape1, shape2])\n",
    "#     yArray = np.zeros([len(dataList)])\n",
    "#     for index, file in enumerate(dataList):\n",
    "#         file = path + file\n",
    "#         try:\n",
    "#             xArray[index] = extractMelSpec(file)\n",
    "#             yArray[index] = file.rsplit(\"/\", 2)[1]\n",
    "#         except ValueError:\n",
    "#             print(index, file, ValueError)\n",
    "#     return (xArray, yArray)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# melTrainData, melTrainLabel = creatMelSpecSets(\n",
    "#     \"./train/\", trainList, extractMelSpec(\"./train/\" + trainList[0]).shape\n",
    "# )\n",
    "\n",
    "# melValidData, melValidLabel = creatMelSpecSets(\n",
    "#     \"./valid/\", validList, extractMelSpec(\"./valid/\" + validList[0]).shape\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.68393677e+02],\n",
       "        [ 1.70615356e+02],\n",
       "        [-8.51688538e+01],\n",
       "        ...,\n",
       "        [ 1.22741458e-05],\n",
       "        [ 2.69229898e+03],\n",
       "        [ 4.38340552e-02]],\n",
       "\n",
       "       [[-2.77341370e+02],\n",
       "        [ 1.77488068e+02],\n",
       "        [-8.89495392e+01],\n",
       "        ...,\n",
       "        [ 2.11430211e-06],\n",
       "        [ 2.40316880e+03],\n",
       "        [ 4.97998814e-02]],\n",
       "\n",
       "       [[-2.76884827e+02],\n",
       "        [ 1.72680237e+02],\n",
       "        [-8.73820877e+01],\n",
       "        ...,\n",
       "        [ 6.79598379e-05],\n",
       "        [ 2.55603262e+03],\n",
       "        [ 5.02216361e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.80193146e+02],\n",
       "        [ 1.24102409e+02],\n",
       "        [-1.14348129e+02],\n",
       "        ...,\n",
       "        [ 1.65024758e-04],\n",
       "        [ 3.30756037e+03],\n",
       "        [ 3.22950003e-02]],\n",
       "\n",
       "       [[-2.95152283e+02],\n",
       "        [ 1.48257584e+02],\n",
       "        [-9.92873383e+01],\n",
       "        ...,\n",
       "        [ 4.32145389e-05],\n",
       "        [ 2.99937012e+03],\n",
       "        [ 3.22624434e-02]],\n",
       "\n",
       "       [[-2.68486206e+02],\n",
       "        [ 1.37189514e+02],\n",
       "        [-1.15576912e+02],\n",
       "        ...,\n",
       "        [ 4.82690593e-05],\n",
       "        [ 3.27304688e+03],\n",
       "        [ 3.81568398e-02]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.reshape(1000, 277, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
